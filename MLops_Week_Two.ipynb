{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) Install MLflow\n",
    "\n",
    "What's the version of MLflow installed\n",
    "\n",
    "Answer:\n",
    "\n",
    "mlflow, version 1.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) Download and Preprocess the Data\n",
    "\n",
    "How many files were saved to OUTPUT_FOLDER\n",
    "\n",
    "Answer:\n",
    "\n",
    "4 pkl files were created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(raw_data_path: str, dest_path: str, dataset: str = \"green\"):\n",
    "    # load parquet files\n",
    "    df_train = read_dataframe(\n",
    "        os.path.join(raw_data_path, f\"{dataset}_tripdata_2021-01.parquet\")\n",
    "    )\n",
    "    df_valid = read_dataframe(\n",
    "        os.path.join(raw_data_path, f\"{dataset}_tripdata_2021-02.parquet\")\n",
    "    )\n",
    "    df_test = read_dataframe(\n",
    "        os.path.join(raw_data_path, f\"{dataset}_tripdata_2021-03.parquet\")\n",
    "    )\n",
    "\n",
    "    # extract the target\n",
    "    target = 'duration'\n",
    "    y_train = df_train[target].values\n",
    "    y_valid = df_valid[target].values\n",
    "    y_test = df_test[target].values\n",
    "\n",
    "    # fit the dictvectorizer and preprocess data\n",
    "    dv = DictVectorizer()\n",
    "    X_train, dv = preprocess(df_train, dv, fit_dv=True)\n",
    "    X_valid, _ = preprocess(df_valid, dv, fit_dv=False)\n",
    "    X_test, _ = preprocess(df_test, dv, fit_dv=False)\n",
    "\n",
    "    # create dest_path folder unless it already exists\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "    # save dictvectorizer and datasets\n",
    "    # CREATES THE FOUR PKL FILES \n",
    "    dump_pickle(dv, os.path.join(dest_path, \"dv.pkl\"))\n",
    "    dump_pickle((X_train, y_train), os.path.join(dest_path, \"train.pkl\"))\n",
    "    dump_pickle((X_valid, y_valid), os.path.join(dest_path, \"valid.pkl\"))\n",
    "    dump_pickle((X_test, y_test), os.path.join(dest_path, \"test.pkl\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) Train a Model with Autolog\n",
    "\n",
    "How many parameters are automatically logged by MLflow?\n",
    "\n",
    "Answer:\n",
    "\n",
    "17 parameters were logged using mlflow.autolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_path):\n",
    "    mlflow.autolog()\n",
    "    # start mlflow\n",
    "    with mlflow.start_run():\n",
    "        # use autolog\n",
    "        mlflow.sklearn.autolog()\n",
    "\n",
    "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "        X_valid, y_valid = load_pickle(os.path.join(data_path, \"valid.pkl\"))\n",
    "\n",
    "        rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_valid)\n",
    "\n",
    "        rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "        mlflow.log_metric('rmse ', rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) Launch The Tracking Server Locally \n",
    "\n",
    "In addition to --backend-store-uri, what else do you need to pass to properly configure the server?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--default-artifact-root:\n",
    "\n",
    "Directory in which to store artifacts for any new experiments created. For tracking server backends that rely on SQL, this option is required in order to store artifacts. Note that this flag does not impact already-created experiments with any previous configuration of an MLflow server instance. By default, data will be logged to the mlflow-artifacts:/ uri proxy if the â€“serve-artifacts option is enabled. Otherwise, the default location will be ./mlruns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5) Tune The Hyperparameters Of The Model\n",
    "\n",
    "The idea is to just log information that you need to answer the question below, including \n",
    "\n",
    "    the list of hyperparameters that are passed to the objective function during the optimization \n",
    "\n",
    "    the RMSE obtained on the validation set(Feb 2021 data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def objective(params):\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            # log the \"model\" tag \n",
    "            # Will log all 50 runs of the models\n",
    "            # mlflow.set_tag(\"model\", \"random-forest\")  \n",
    "\n",
    "            # log all the hyperparameters that got passed into this function\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_valid)\n",
    "\n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "            # log rmse\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best validation RMSE that you got\n",
    "\n",
    "Duration\n",
    "\n",
    "10.1s to Train \n",
    "\n",
    "Metrics\n",
    "\n",
    "RSME: 6.628\n",
    "\n",
    "Parameters\n",
    "\n",
    "max_depth: 19\n",
    "\n",
    "min_samples_leaf: 3\n",
    "\n",
    "min_samples_split: 5\n",
    "\n",
    "n_estimators: 28\n",
    "\n",
    "random_state: 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6) Promote the Best Model to The Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_path, log_top):\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # retrieve the top_n model runs and log the models to MLflow\n",
    "    experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=log_top,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    "    )\n",
    "    for run in runs:\n",
    "        train_and_log_model(data_path=data_path, params=run.data.params)\n",
    "\n",
    "    # select the model with the lowest test RMSE\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "\n",
    "        experiment_ids=experiment.experiment_id, #grab the experiment id\n",
    "        run_view_type=ViewType.ACTIVE_ONLY, # \n",
    "        max_results=1, #Promote one model \n",
    "        order_by=[\"metrics.test_rmse ASC\"] #Order by rmse\n",
    "    )[0]\n",
    "\n",
    "    # register the best model\n",
    "    run_id = best_run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    mlflow.register_model(model_uri = model_uri, name=\"greentaxi_regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the Test RMSE of the Best Model\n",
    "\n",
    "Best RMSE:\n",
    "\n",
    "6.548\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4f34fe5c50d81fd0e32d9bf54bf6651f7e0c1c79be719023e70b23d8e2148a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('mlflow_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
